# Remove intermediate objects generated by model creation
# This is done to recover limited memory resources consumed by large objects
rm_intermediate <- function(x, keep = NULL) {
  env <- ls(envir = .GlobalEnv)
  rm_list <- env[
    str_starts(env, x) & !str_detect(env, "final") & !env %in% keep
  ]
  
  if (length(rm_list) > 0) {
    message(paste(
      "Removing intermediate objects:",
      paste(rm_list, collapse = ", ")
    ))
    rm(list = rm_list, envir = .GlobalEnv); gc()
  }
}

# Return prediction from a model and recipe
model_predict <- function(model, recipe, data) {
  exp(predict(
    model,
    new_data = bake(recipe, data) %>%
      select(-ends_with("_sale_price"))
  )$.pred)
}


# Get environmental variable else a specified default value
model_get_env <- function(x, default) {
  env <- Sys.getenv(x, unset = NA)
  ifelse(!is.na(env), env, default)
} 


# Remove data from iteration results objects created by tune_grid and tune_bayes
model_strip_data <- function(x) {
  stripped <- x %>% select(-any_of("splits"))
  
  attrs <- attributes(x) %>%
    purrr::list_modify("names" = names(stripped))
  attributes(stripped) <- attrs
  stripped
}


# Create a stacked model object containing each fitted model, its corresponding
# recipe, a metamodel, and the training data
stack_model <- function(models, recipes, meta_spec, data, add_vars = NULL) {
  
  # Check that names match for models and recipes
  stopifnot(
    all(names(models) %in% names(recipes)),
    all(names(recipes) %in% names(models))
  )

  # Get fits for all models
  meta_train <- pmap(list(models, recipes), ~ model_predict(.x, .y, data))
  
  # Create a recipe for the meta model
  meta_recipe <- stack_recp_prep(
    bind_cols(meta_train, data),
    keep_vars = c(names(models), add_vars)
  )
 
  # Prep the data for fitting in the meta model
  prepped <- prep(meta_recipe)
  x <- juice(prepped, all_predictors())
  y <- juice(prepped, all_outcomes())
  
  # Fit the meta model on the predictions of the other models + town_code
  meta_fit <-  fit_xy(meta_spec, x = x, y = y)

  # Return original models, recipes, and meta fit
  meta <- list(
    models = models,
    recipes = recipes,
    meta_fit = meta_fit,
    meta_recipe = meta_recipe
  )
  class(meta) <- "stack_model"
  meta
}


# S3 predict method for stack model object
predict.stack_model <- function(object, new_data) {
  
  # Predict on new data using previously fitted models
  new_preds <- pmap(
    list(object$models, object$recipes), ~ model_predict(.x, .y, new_data)
  )

  # Get predictions from the stacked model using predictions as inputs
  stack_preds <- exp(predict(
    object$meta_fit,
    bake(prep(object$meta_recipe), bind_cols(new_preds, new_data)) %>%
      select(-ends_with("_sale_price")) # Fix glmnet not removing outcome var
  ))
  
  # Output other model predictions + stacked predictions in a single list
  c(new_preds, stack = list(stack_preds$.pred))
}
