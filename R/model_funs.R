# Remove intermediate objects generated by model creation
# This is done to recover limited memory resources consumed by large objects
rm_intermediate <- function(x, keep = NULL) {
  env <- ls(envir = .GlobalEnv)
  rm_list <- env[
    str_starts(env, x) & !str_detect(env, "final") & !env %in% keep
  ]
  
  if (length(rm_list) > 0) {
    message(paste(
      "Removing intermediate objects:",
      paste(rm_list, collapse = ", ")
    ))
    rm(list = rm_list, envir = .GlobalEnv); gc()
  }
}

# Return prediction from a model and recipe
model_predict <- function(spec, recipe, data) {
  exp(predict(
    spec,
    new_data = bake(recipe, data) %>%
      select(-ends_with("_sale_price"))
  )$.pred)
}


# Get environmental variable else a specified default value
model_get_env <- function(x, default) {
  env <- Sys.getenv(x, unset = NA)
  ifelse(!is.na(env), env, default)
} 


# Remove data from iteration results objects created by tune_grid and tune_bayes
model_strip_data <- function(x) {
  stripped <- x %>% select(-any_of("splits"))
  
  attrs <- attributes(x) %>%
    purrr::list_modify("names" = names(stripped))
  attributes(stripped) <- attrs
  stripped
}


# Create a stacked model object containing each fitted model, its corresponding
# recipe, a metamodel, and the training data
stack_model <- function(specs, recipes, meta_spec, meta_keep_vars = NULL, data) {
  
  # Check that names match for specs and recipes
  stopifnot(
    all(names(specs) %in% names(recipes)),
    all(names(recipes) %in% names(specs))
  )

  # Get fits for all specs
  meta_train_fits <- pmap(list(specs, recipes), ~ model_predict(.x, .y, data))
  
  # Create a recipe for the meta model
  meta_recipe <- stack_recp_prep(
    bind_cols(meta_train_fits, data),
    keep_vars = c(names(specs), meta_keep_vars)
  )
 
  # Prep the data for fitting in the meta model
  prepped <- prep(meta_recipe)
  x <- juice(prepped, all_predictors())
  y <- juice(prepped, all_outcomes())
  
  # Fit the meta model on the predictions of the other specs + town_code
  meta_fit <-  fit_xy(meta_spec, x = x, y = y)
  
  # Prep meta recipe for export with model and remove training data
  meta_recipe_prepped <- prep(meta_recipe, retain = FALSE)
  meta_recipe_prepped$template <- NULL

  # Return original specs, recipes, and meta fit
  meta <- list(
    specs = specs,
    recipes = recipes,
    meta_fit = meta_fit,
    meta_recipe = meta_recipe_prepped
  )
  class(meta) <- "stack_model"
  meta
}


# S3 predict method for stack model object
predict.stack_model <- function(object, new_data) {
  
  # Predict on new data using previously fitted specs
  new_preds <- pmap(
    list(object$specs, object$recipes), ~ model_predict(.x, .y, new_data)
  )

  # Get predictions from the stacked model using predictions as inputs
  stack_preds <- exp(predict(
    object$meta_fit,
    bake(object$meta_recipe, bind_cols(new_preds, new_data)) %>%
      select(-ends_with("_sale_price")) # Fix glmnet not removing outcome var
  ))
  
  # Output other model predictions + stacked predictions in a single list
  c(new_preds, stack = list(stack_preds$.pred))
}
