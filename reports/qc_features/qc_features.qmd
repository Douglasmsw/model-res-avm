---
title: "Input QC and Feature Investigation"
execute:
  echo: false
  warning: false
format:
  html:
    page-layout: full
    toc: true
    toc_float: true
    fig-align: center
    fontsize: 12pt
editor: source
---

```{r setup}

# This script runs balance tests comparing the universe of residential parcels
# to the sample of residential parcels with sales in the previous 8 years
# that are used to train the data department's CAMA.

# Load necessary libraries
library(arrow)
library(DBI)
library(dplyr)
library(DT)
library(ggplot2)
library(glue)
library(kableExtra)
library(leaflet)
library(noctua)
library(plotly)
library(scales)
library(sf)
library(skimr)
library(stringr)
library(tableone)
library(tidyr)

options(knitr.kable.NA = '')
options(scipen = 999)
options(width = 150)

# Connect to Athena
AWS_ATHENA_CONN_NOCTUA <- dbConnect(noctua::athena())

# Data paths
data_path <- "~/data/shaps.parquet"
centroids_path <- "~/data/centroids.parquet"

# Ingest training set
training_data <- read_parquet("~/ccao_res_avm/input/training_data.parquet")

# Declare model IDs
model_ids <- c('2023-02-03-vigilant-tayun', '2023-01-31-unruffled-kyra')

pull_ids <- glue_collapse(model_ids, sep = "', '")

# Ingest shap values
if (!file.exists(data_path)) {
  
  dbGetQuery(
  conn = AWS_ATHENA_CONN_NOCTUA,
  glue("

    SELECT *
      FROM model.shap
      WHERE run_id IN ('{pull_ids}')

  ")
) %>%
  write_parquet(data_path)
  
}

shaps <- read_parquet(data_path) %>%
  slice_sample(n = 50000)

# Ingest centroids
if (!file.exists(centroids_path)) {
  
  dbGetQuery(
  conn = AWS_ATHENA_CONN_NOCTUA,
  "
  SELECT pin as meta_pin, lon, lat
    FROM default.vw_pin_universe
    WHERE year = '2022'
  "
) %>%
  write_parquet(centroids_path)
  
}

centroids <- read_parquet(centroids_path)

```

## Sales Sample

::: {.panel-tabset}

## Township/Year

``` {r town_year}

township <- training_data %>%
  mutate(meta_year = as.numeric(meta_year)) %>%
  group_by(meta_township_name, meta_year) %>%
  summarise(sales = n()) %>%
  select(Sales = sales, Year = meta_year, Township = meta_township_name) %>%
  ggplot() +
  geom_line(aes(x = Year, y = Sales, color = Township)) +
  theme_minimal() +
  scale_y_continuous(labels = scales::comma, breaks = seq(0, 6000, 1000)) +
  scale_x_continuous(breaks = seq(2014, 2022, 1)) +
  theme(
    legend.position = "none",
    axis.title.x = element_blank()
  )
  
ggplotly(township)

```

## Class/Year

``` {r class_year}

class <- training_data %>%
  mutate(meta_year = as.numeric(meta_year)) %>%
  group_by(meta_class, meta_year) %>%
  summarise(sales = n()) %>%
  rename(Class = meta_class) %>%
  pivot_wider(id_cols = Class, names_from = meta_year, values_from = sales)

class  %>%
  kable() %>%
  kable_styling() %>%
  row_spec(
    unique(which(is.na(class), arr.ind = TRUE)[,1]),
    bold = T,
    background = "lightgrey"
    )

```
:::

## Shap Values

``` {r chars}

shap_tables <- shaps %>%
  split(.$run_id) %>%
  lapply(function(x) {
    
    x %>%
      select(where(~ !all(is.na(.x))) & !starts_with("pred") & where(is.numeric)) %>%
      skim() %>%
      rename_with(~ str_replace_all(.x, "skim_|numeric.", "")) %>%
      select(-c(type, n_missing, complete_rate, p25, p75)) %>%
      rename("histogram" = "hist", "median" = "p50", "min" = "p0", "max" = "p100") %>%
      mutate(
        variable = str_replace_all(variable, "_", " "),
        across(where(is.numeric), ~ round(.x, 1)),
        `mean direction` = case_when(
          mean < 0 ~ "-", mean > 0 ~ "+", TRUE ~ ""
          ),
        `median direction` = case_when(
          median < 0 ~ "-", median > 0 ~ "+", TRUE ~ ""
          ),
        mean = abs(mean),
        median = abs(median)
        ) %>%
      relocate(`mean direction`, .before = mean) %>%
      relocate(`median direction`, .before = median) %>%
      datatable(
        rownames = FALSE,
        height = "500px",
        options = list(
                columnDefs = list(
                  list(className = 'dt-center', targets = c(1:7))
                  )
                )
        )
    
  })

```

::: {.panel-tabset}

## `r names(shap_tables)[1]`

``` {r}

shap_tables[[1]]

```

## `r names(shap_tables)[2]`

``` {r}

shap_tables[[2]]

```

:::

### Consistency Across Runs

#### Median and Standard Deviation

``` {r}

model_ids %>%
  lapply(function(x) {
    
    shaps %>% filter(run_id == !!x) %>%
    select(where(~ !all(is.na(.x))) & !starts_with("pred") & where(is.numeric)) %>%
    skim() %>%
    rename_with(~ str_replace_all(.x, "skim_|numeric.", "")) %>%
    select(variable, median = p50, sd) %>%
    mutate(run_id = x)
    
  }) %>%
  bind_rows() %>%
  pivot_wider(values_from = c(median, sd), names_from = run_id) %>%
  mutate(
    variable = str_replace_all(variable, "_", " "),
    median_difference = .[[2]] - .[[3]],
    sd_difference = .[[4]] - .[[5]]
    ) %>%
  select(1, 2, 3, 6, 4, 5, 7) %>%
  kable(
    col.names = c("Feature", rep(c(model_ids, "Difference"), 2))
  ) %>%
  kable_styling(
    "striped"
  ) %>%
  add_header_above(c("", "Median" = 3, "Standard Deviation" = 3))

```

#### Standardized Mean Difference

The standardized (mean) difference is a measure of distance between two group means in terms of one or more variables.

$$SMD = {\text{Difference in mean outcome between groups} \over \text{Standard deviation of outcome among participants}}$$

We're looking for SMDs greater than .1 or .05 for sensitive covariates.


``` {r}

vars <- names(
  shaps %>%
  select(where(~ !all(is.na(.x))) & !starts_with("pred") & where(is.numeric))
)

smd_table <- CreateTableOne(
  vars = vars,
  strata = "run_id",
  data = shaps,
  test = FALSE,
  includeNA = TRUE
)

print(smd_table, smd = TRUE)

```

### Outliers

``` {r}

top5 <- shaps %>%
  select(where(~ !all(is.na(.x))) & !starts_with("pred") & where(is.numeric), run_id) %>%
  group_by(run_id) %>%
  summarise(across(.cols = everything(), ~ median(.x, na.rm = TRUE))) %>%
  pivot_longer(cols = !run_id, values_to = "median", names_to = "feature") %>%
  pivot_wider(values_from = "median", names_from = "run_id")

top5 <- top5 %>%
  filter(feature %in% unique(c(
       top5 %>%
         arrange(desc(abs(.[[2]]))) %>%
         slice_head(n = 5) %>%
         pull(feature),
       top5 %>%
         arrange(desc(abs(.[[3]]))) %>%
         slice_head(n = 5) %>%
         pull(feature)
         ))) %>%
  pull(feature
       )

outliers_detect <- function(x) {
  
  median <- median(x, na.rm = TRUE)
  
  mad <- mad(x, constant = 1, na.rm = TRUE)
  
  x < median - 3 * mad | x > median + 3 * mad
  
}

top5_outliers <- shaps %>%
  select(meta_pin, !!top5) %>%
  mutate(across(!!top5, ~ outliers_detect(.x), .names = "{.col}_outlier")) %>%
  left_join(centroids) %>%
  filter(!is.na(lat)) %>%
  st_as_sf(coords = c("lon", "lat"), crs = 4326)

temp <- lapply(top5, function(x) {
  
  top5_outliers %>% 
    select(contains(x)) %>%
    filter(.[[2]])
  
})

```

### Spatial Distribution

``` {r}

```

:::
