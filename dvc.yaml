stages:
  ingest:
    cmd: Rscript pipeline/00-ingest.R
    desc: >
      Ingest training and assessment data from Athena + generate townhome
      complex identifiers
    params:
    - assessment
    - input
    outs:
    - input/training_data.parquet:
        desc: "Sales data used to train the model"
    - input/assessment_data.parquet:
        desc: "All residential properties in Cook County"
    - input/complex_id_data.parquet:
        desc: "Townhome complex identifiers constructed with fuzzy grouping"
    - input/land_site_rate_data.parquet:
        desc: "PIN-level land values provided by Valuations"
    - input/land_nbhd_rate_data.parquet:
        desc: "Neighborhood-level land rates provided by Valuations"

  train:
    cmd: Rscript pipeline/01-train.R
    desc: >
      Train a LightGBM model with cross-validation. Generate model objects,
      data recipes, and predictions on the test set (most recent 10% of sales)
    deps:
    - input/training_data.parquet
    params:
    - toggle.cv_enable
    - cv
    - model.engine
    - model.objective
    - model.seed
    - model.verbose
    - model.predictor
    - model.parameter
    - model.hyperparameter.range
    outs:
    - output/parameter_final/model_parameter_final.parquet:
        cache: false
        desc: "Final hyperparameters chosen using tune::select_best()"
    - output/parameter_range/model_parameter_range.parquet:
        cache: false
        desc: "Parameter space searched by cross-validation"
    - output/parameter_search/model_parameter_search.parquet:
        cache: false
        desc: "Raw output from Tidymodels cross-validation"
    - output/workflow/fit/model_workflow_fit.zip:
        cache: false
        desc: "LightGBM model object + Tidymodels parsnip specification"
    - output/workflow/recipe/model_workflow_recipe.rds:
        cache: false
        desc: "Tidymodels recipe for to prepare new input data"
    - output/intermediate/timing/model_timing_train.parquet:
        cache: false
        
  assess:
    cmd: Rscript pipeline/02-assess.R
    desc: >
      Use the trained model to estimate sale prices for all PINS/cards in Cook
      County. Also generate flags, calculate land values, and make any
      post-modeling changes
    deps:
    - input/training_data.parquet
    - input/assessment_data.parquet
    - input/complex_id_data.parquet
    - input/land_site_rate_data.parquet
    - input/land_nbhd_rate_data.parquet
    - output/workflow/fit/model_workflow_fit.zip
    - output/workflow/recipe/model_workflow_recipe.rds
    params:
    - assessment
    - pv
    - ratio_study
    - model.predictor.all
    outs:
    - output/assessment_card/model_assessment_card.parquet:
        cache: false
        desc: "Card-level predicted values for all residential properties"
    - output/assessment_pin/model_assessment_pin.parquet:
        cache: false
        desc: "PIN-level predicted values (land, YoY delta, prior years, etc.)"
    - output/intermediate/model_assessment.parquet:
        cache: false
        desc: "PIN-level predicted values saved temporarily for evaluate stage"
    - output/intermediate/timing/model_timing_assess.parquet:
        cache: false
        
  evaluate:
    cmd: Rscript pipeline/03-evaluate.R
    desc: >
      Evaluate the model's performance using two methods:
        1. The standard test set, in this case the most recent 10% of sales
        2. An assessor-specific ratio study comparing estimated assessments to
           the previous year's sales
    deps:
    - output/intermediate/model_test.parquet
    - output/intermediate/model_assessment.parquet
    params:
    - run_type
    - assessment.data_year
    - ratio_study
    outs:
    - output/performance/model_performance_test.parquet:
        cache: false
        desc: "Performance stats on the test set by geography and class"
    - output/performance_quantile/model_performance_quantile_test.parquet:
        cache: false
        desc: "Performance stats on the test set by geography and quantile"
    - output/performance/model_performance_assessment.parquet:
        cache: false
        desc: "Performance stats on the assessment set by geography and class"
    - output/performance_quantile/model_performance_quantile_assessment.parquet:
        cache: false
        desc: "Performance stats on the assessment set by geography and quantile"
    - output/intermediate/timing/model_timing_evaluate.parquet:
        cache: false
        
  interpret:
    cmd: Rscript pipeline/04-interpret.R
    desc: >
      Generate SHAP values for each card and feature in the assessment data
    deps:
    - input/assessment_data.parquet
    - output/workflow/fit/model_workflow_fit.zip
    - output/workflow/recipe/model_workflow_recipe.rds
    params:
    - model.predictor.all
    outs:
    - output/shap/model_shap.parquet:
        cache: false
        desc: "SHAP values for all feature and cards in the assessment data"
    - output/intermediate/timing/model_timing_interpret.parquet:
        cache: false
        
  finalize:
    cmd: Rscript pipeline/05-finalize.R
    desc: >
       Save run timings, upload pipeline run results to S3, and send an SNS
       notification. Will also clean some of the generated outputs prior to
       upload and attach a unique run ID
    deps:
    - output/parameter_final/model_parameter_final.parquet
    - output/parameter_range/model_parameter_range.parquet
    - output/parameter_search/model_parameter_search.parquet
    - output/workflow/fit/model_workflow_fit.zip
    - output/workflow/recipe/model_workflow_recipe.rds
    - output/assessment_card/model_assessment_card.parquet
    - output/assessment_pin/model_assessment_pin.parquet
    - output/intermediate/model_assessment.parquet
    - output/performance/model_performance_test.parquet
    - output/performance_quantile/model_performance_quantile_test.parquet
    - output/performance/model_performance_assessment.parquet
    - output/performance_quantile/model_performance_quantile_assessment.parquet
    - output/shap/model_shap.parquet
    - output/intermediate/timing/model_timing_train.parquet
    - output/intermediate/timing/model_timing_assess.parquet
    - output/intermediate/timing/model_timing_evaluate.parquet
    - output/intermediate/timing/model_timing_interpret.parquet
    params:
    - run_note
    - run_type
    - toggle
    - input
    - cv
    - model
    - pv
    - ratio_study
    outs:
    - output/timing/model_timing.parquet:
        cache: false
        desc: "Individual timing files aggregated into a single-row data frame"